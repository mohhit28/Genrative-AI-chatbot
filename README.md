# Gen-AI-With-Deep-Seek-R1
# ğŸ§  DeepSeek Code Companion
ğŸš€ Your AI Pair Programmer with Debugging Superpowers

# ğŸ“Œ Overview
DeepSeek Code Companion is an AI-powered coding assistant designed to help developers with:
âœ… Writing Python code
âœ… Debugging and troubleshooting
âœ… Code documentation
âœ… Solution design

This project leverages Streamlit for the UI, LangChain for handling LLM interactions, and Ollama for local model execution.

# âš™ï¸ Tech Stack
Streamlit â€“ Interactive UI for chat interface
LangChain â€“ Manages LLM prompt processing
Ollama â€“ Runs DeepSeek AI models locally
Python â€“ Backend logic
ğŸ“‚ Project Structure
css
Copy
Edit
ğŸ“¦ DeepSeek-Code-Companion
â”‚â”€â”€ ğŸ“œ README.md
â”‚â”€â”€ ğŸ“œ requirements.txt
â”‚â”€â”€ ğŸ“œ app.py
â”‚â”€â”€ ğŸ“‚ models
â”‚â”€â”€ ğŸ“‚ data
â”‚â”€â”€ ğŸ“‚ assets
# ğŸš€ Setup & Installation
1ï¸âƒ£ Clone the repository
bash
Copy
Edit
git clone https://github.com/your-username/deepseek-code-companion.git
cd deepseek-code-companion
# 2ï¸âƒ£ Install dependencies
bash
Copy
Edit
# pip install -r requirements.txt
3ï¸âƒ£ Run Ollama (if not installed, install it first)
bash
Copy
Edit
ollama serve
# 4ï¸âƒ£ Start the Streamlit app
bash
Copy
Edit
streamlit run app.py
ğŸ— Features
âœ… Interactive Chat Interface â€“ Ask coding questions in natural language
âœ… AI-Powered Debugging â€“ Get strategic print statements for debugging
âœ… Multiple LLM Models â€“ Choose from deepseek-r1:1.5b or deepseek-r1:3b
âœ… Code Explanation & Documentation â€“ Understand code better

# ğŸ¨ Customization
ğŸ”¹ Modify Model Settings
You can adjust the LLM temperature for different response behaviors:

python
Copy
Edit
llm_engine = ChatOllama(
    model=selected_model,
    base_url="http://localhost:11434",
    temperature=0.3
)
Lower values = deterministic responses
Higher values = more creative responses

# ğŸ”¹ Modify UI Theme
Custom CSS is included for a dark-themed UI. Modify styles in app.py under:

python
Copy
Edit
st.markdown("""
<style>
    .main { background-color: #1a1a1a; color: #ffffff; }
</style>
""", unsafe_allow_html=True)
ğŸ’¡ Usage Guide
1ï¸âƒ£ Select an LLM model from the sidebar
2ï¸âƒ£ Type a coding question in the chat box
3ï¸âƒ£ View AI-generated solutions & explanations
4ï¸âƒ£ Use debugging suggestions to fix errors

ğŸ›  Future Improvements
ğŸš€ Add support for more programming languages
ğŸš€ Implement code execution sandbox
ğŸš€ Improve UI/UX with better chat history management

ğŸ¤ Contributing
Contributions are welcome! Open a pull request or submit an issue to suggest improvements.

# ğŸ“œ License
This project is licensed under the MIT License.
